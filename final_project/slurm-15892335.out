Loading fashion-mnist data... done
Loading model...[18:28:48] src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.11.0. Attempting to upgrade...
[18:28:48] src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!
==13182== NVPROF is profiling process 13182, command: python submit/submission.py
 done
New Inference
Op Time: 2.760084
Op Time: 10.818533
Correctness: 0.7955 Model: eecs498
==13182== Profiling application: python submit/submission.py
==13182== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   98.84%  13.5782s         2  6.78910s  2.75982s  10.8184s  mxnet::op::forward_kernel(float*, float const *, int, int, int, int, int, int)
                    0.97%  132.91ms        20  6.6453ms  1.1200us  130.60ms  [CUDA memcpy HtoD]
                    0.08%  11.060ms         2  5.5298ms  1.9113ms  9.1484ms  void mshadow::cuda::MapPlanLargeKernel<mshadow::sv::saveto, int=8, int=1024, mshadow::expr::Plan<mshadow::Tensor<mshadow::gpu, int=4, float>, float>, mshadow::expr::Plan<mshadow::expr::BinaryMapExp<mshadow::op::mul, mshadow::expr::ScalarExp<float>, mshadow::Tensor<mshadow::gpu, int=4, float>, float, int=1>, float>>(mshadow::gpu, unsigned int, mshadow::Shape<int=2>, int=4, int)
                    0.05%  6.6044ms         1  6.6044ms  6.6044ms  6.6044ms  volta_sgemm_128x128_tn
                    0.04%  5.3843ms         2  2.6922ms  18.016us  5.3663ms  void op_generic_tensor_kernel<int=1, float, float, float, int=256, cudnnGenericOp_t=7, cudnnNanPropagation_t=0, int=1>(cudnnTensorStruct, float*, cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, float, float, float, float, reducedDivisorArray, int)
                    0.02%  3.3856ms         1  3.3856ms  3.3856ms  3.3856ms  void cudnn::detail::pooling_fw_4d_kernel<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, int=0, bool=0>(cudnnTensorStruct, float const *, cudnn::detail::pooling_fw_4d_kernel<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, int=0, bool=0>, cudnnTensorStruct*, cudnnPoolingStruct, float, cudnnPoolingStruct, int, cudnn::reduced_divisor, float)
                    0.00%  320.48us         1  320.48us  320.48us  320.48us  void mshadow::cuda::MapPlanLargeKernel<mshadow::sv::saveto, int=8, int=1024, mshadow::expr::Plan<mshadow::Tensor<mshadow::gpu, int=2, float>, float>, mshadow::expr::Plan<mshadow::expr::ScalarExp<float>, float>>(mshadow::gpu, unsigned int, mshadow::Shape<int=2>, int=2, int)
                    0.00%  56.255us        13  4.3270us  1.2160us  20.800us  void mshadow::cuda::MapPlanKernel<mshadow::sv::saveto, int=8, mshadow::expr::Plan<mshadow::Tensor<mshadow::gpu, int=2, float>, float>, mshadow::expr::Plan<mshadow::expr::ScalarExp<float>, float>>(mshadow::gpu, unsigned int, mshadow::Shape<int=2>, int=2)
                    0.00%  48.736us         1  48.736us  48.736us  48.736us  void mshadow::cuda::SoftmaxKernel<int=8, float, mshadow::expr::Plan<mshadow::Tensor<mshadow::gpu, int=2, float>, float>, mshadow::expr::Plan<mshadow::Tensor<mshadow::gpu, int=2, float>, float>>(mshadow::gpu, int=2, unsigned int)
                    0.00%  26.752us         1  26.752us  26.752us  26.752us  volta_sgemm_32x32_sliced1x4_tn
                    0.00%  19.296us         2  9.6480us  2.3360us  16.960us  void mshadow::cuda::MapPlanKernel<mshadow::sv::plusto, int=8, mshadow::expr::Plan<mshadow::Tensor<mshadow::gpu, int=2, float>, float>, mshadow::expr::Plan<mshadow::expr::Broadcast1DExp<mshadow::Tensor<mshadow::gpu, int=1, float>, float, int=2, int=1>, float>>(mshadow::gpu, unsigned int, mshadow::Shape<int=2>, int=2)
                    0.00%  9.4080us         8  1.1760us  1.0560us  1.6000us  [CUDA memset]
                    0.00%  5.7920us         1  5.7920us  5.7920us  5.7920us  [CUDA memcpy DtoH]
                    0.00%  5.7280us         2  2.8640us  2.7520us  2.9760us  [CUDA memcpy DtoD]
                    0.00%  4.5440us         1  4.5440us  4.5440us  4.5440us  void mshadow::cuda::MapPlanKernel<mshadow::sv::saveto, int=8, mshadow::expr::Plan<mshadow::Tensor<mshadow::gpu, int=2, float>, float>, mshadow::expr::Plan<mshadow::expr::ReduceWithAxisExp<mshadow::red::maximum, mshadow::Tensor<mshadow::gpu, int=3, float>, float, int=3, bool=1, int=2>, float>>(mshadow::gpu, unsigned int, mshadow::Shape<int=2>, int=2)
      API calls:   55.54%  13.5894s         8  1.69867s  4.5690us  10.8184s  cudaDeviceSynchronize
                   19.16%  4.68816s        22  213.10ms  2.4280us  2.35403s  cudaStreamCreateWithFlags
                   16.35%  4.00040s        22  181.84ms  14.010us  3.99969s  cudaMemGetInfo
                    7.61%  1.86321s        18  103.51ms     349ns  504.35ms  cudaFree
                    1.05%  257.31ms         9  28.589ms  5.8900us  134.68ms  cudaMemcpy2DAsync
                    0.11%  26.913ms        27  996.78us  13.424us  25.618ms  cudaLaunchKernel
                    0.06%  13.790ms        29  475.50us  1.5080us  7.7127ms  cudaStreamSynchronize
                    0.05%  12.450ms        66  188.64us  3.4290us  2.9629ms  cudaMalloc
                    0.04%  8.8007ms         4  2.2002ms  7.9750us  8.7236ms  cudaStreamCreate
                    0.01%  2.7562ms         4  689.04us  29.614us  2.6556ms  cuDeviceGetName
                    0.01%  1.5253ms         4  381.33us  366.90us  402.73us  cuDeviceTotalMem
                    0.00%  1.1205ms         2  560.26us  19.421us  1.1011ms  cudaHostAlloc
                    0.00%  941.17us       375  2.5090us     122ns  108.93us  cuDeviceGetAttribute
                    0.00%  927.31us         4  231.83us  216.86us  257.06us  cudaGetDeviceProperties
                    0.00%  284.20us       384     740ns     364ns  9.1270us  cudaFuncSetAttribute
                    0.00%  181.62us         8  22.702us  7.3500us  71.384us  cudaMemsetAsync
                    0.00%  181.40us         2  90.701us  62.425us  118.98us  cudaMemcpyToSymbol
                    0.00%  165.88us        12  13.823us  6.2970us  39.097us  cudaMemcpy
                    0.00%  140.08us       216     648ns     400ns  5.1000us  cudaEventCreateWithFlags
                    0.00%  79.137us       206     384ns     257ns  3.4110us  cudaDeviceGetAttribute
                    0.00%  69.515us        27  2.5740us     473ns  8.9130us  cudaSetDevice
                    0.00%  38.013us         8  4.7510us  2.2830us  17.489us  cudaStreamCreateWithPriority
                    0.00%  30.253us        18  1.6800us     280ns  5.4830us  cudaGetDevice
                    0.00%  15.838us        20     791ns     301ns  4.6910us  cudaPeekAtLastError
                    0.00%  10.690us         2  5.3450us  4.4300us  6.2600us  cudaEventRecord
                    0.00%  10.675us         5  2.1350us     421ns  5.2130us  cudaGetLastError
                    0.00%  10.352us         2  5.1760us  2.4450us  7.9070us  cudaDeviceGetStreamPriorityRange
                    0.00%  8.5150us         6  1.4190us     680ns  4.3240us  cudaEventCreate
                    0.00%  5.6910us         1  5.6910us  5.6910us  5.6910us  cuDeviceGetPCIBusId
                    0.00%  5.0570us         4  1.2640us     203ns  2.1230us  cudaGetDeviceCount
                    0.00%  4.4260us         2  2.2130us  1.0770us  3.3490us  cudaHostGetDevicePointer
                    0.00%  2.1550us         3     718ns     628ns     768ns  cuInit
                    0.00%  2.1140us         5     422ns     204ns     574ns  cuDeviceGet
                    0.00%  2.0550us         6     342ns     132ns     953ns  cuDeviceGetCount
                    0.00%     750ns         3     250ns     215ns     306ns  cuDriverGetVersion
